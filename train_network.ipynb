{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from single_label_network import SingleLabelNetworkTrainer\n",
    "from train_utils import get_unused_dir_num\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from train_utils import get_unused_dir_num\n",
    "from train_utils import get_unused_log_dir_num\n",
    "from train_utils import load_images\n",
    "from train_utils import make_logging_callbacks\n",
    "from train_utils import modify_base_model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_width = 28\n",
    "image_height = 28\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "init_lr = None\n",
    "train_file_path = 'test_data/vegetables_001/train_list.txt'\n",
    "val_file_path = None\n",
    "val_file_path = 'test_data/vegetables_001/val_list.txt'\n",
    "model_path = 'lenet'\n",
    "logs_dir = None\n",
    "full_training = True\n",
    "resume = False\n",
    "classes_file_path = os.path.join(os.path.dirname(train_file_path), \"classes.txt\")\n",
    "binary_classification = False\n",
    "if logs_dir is None:\n",
    "    logs_dir = os.path.join(\"logs\", get_unused_dir_num(\"logs\",train_file_path.split('/')[-2] + '_' + model_path))\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "    \n",
    "class_names = []\n",
    "with open(classes_file_path) as classes_fp:\n",
    "    class_names = [line.strip() for line in classes_fp]\n",
    "    num_classes = len(class_names)\n",
    "num_classes = len(class_names)\n",
    "    \n",
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "if model_path == 'lenet':\n",
    "    from lenet import LeNet\n",
    "    base_model = LeNet.build(width=image_width, height=image_height, depth=3, classes=num_classes)\n",
    "elif model_path == 'mobilenet':\n",
    "    from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "    base_model = MobileNet(include_top=True, weights='imagenet')\n",
    "elif model_path == 'inception_v3':\n",
    "    from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "    if image_height == image_width:\n",
    "        base_model = InceptionV3(include_top=True, weights='imagenet')\n",
    "    else:\n",
    "        base_model = InceptionV3(include_top=True, weights='imagenet', input_tensor=Input(shape=(image_height, image_width, 3)))\n",
    "elif model_path == 'EfficientNetB7':\n",
    "    from tensorflow.keras.applications.efficientnet import EfficientNetB7     \n",
    "    if image_height == image_width:  \n",
    "        base_model = EfficientNetB7(include_top=True, weights='imagenet')\n",
    "    else:\n",
    "        base_model = EfficientNetB7(include_top=True, weights='imagenet', input_tensor=Input(shape=(image_height, image_width, 3)))\n",
    "elif model_path == 'NasNet':\n",
    "    from tensorflow.keras.applications.nasnet import NasNet     \n",
    "    if image_height == image_width:  \n",
    "        base_model = NasNet(include_top=True, weights='imagenet')\n",
    "    else:\n",
    "        base_model = NasNet(include_top=True, weights='imagenet', input_tensor=Input(shape=(image_height, image_width, 3)))\n",
    "else:\n",
    "    base_model = load_model(model_path)\n",
    "\n",
    "if init_lr is None:\n",
    "    init_lr = 1e-3 if full_training else 1e-5\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compile_model(optimizer, num_classes, full_training,\n",
    "                  resume, binary):\n",
    "    model = modify_base_model(base_model, 'sigmoid' if num_classes == 1 else 'softmax', num_classes,\n",
    "                              full_training, resume)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mean_squared_error' if binary else 'binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def load_dataset():\n",
    "    print(\"[INFO] loading images...\")\n",
    "    train_paths = []\n",
    "    train_labels = []\n",
    "\n",
    "    with open(train_file_path) as train_fp:\n",
    "        for line in train_fp:\n",
    "            img_path, class_ids = line.split()\n",
    "\n",
    "            train_paths.append(img_path)\n",
    "            train_labels.append(int(class_ids))\n",
    "\n",
    "    with open(classes_file_path) as classes_fp:\n",
    "        class_names = [line.strip() for line in classes_fp]\n",
    "        num_classes = len(class_names)\n",
    "\n",
    "    with open(os.path.join(logs_dir, \"classes.txt\"), 'w') as f:\n",
    "        for item in class_names:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    trainX = load_images(train_paths, image_width, image_height)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # partition the data into training and testing splits using 75% of\n",
    "    # the data for training and the remaining 25% for testing\n",
    "    trainX, testX, trainY, testY = train_test_split(\n",
    "        trainX, train_labels, test_size=0.25, shuffle=True, random_state=42)\n",
    "    print(trainY)\n",
    "    print(testY)\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "    trainY = to_categorical(trainY, num_classes=num_classes)\n",
    "    testY = to_categorical(testY, num_classes=num_classes)\n",
    "\n",
    "    return trainX, testX, trainY, testY, class_names\n",
    "\n",
    "\n",
    "def load_train_val():\n",
    "    print(\"[INFO] loading images...\")\n",
    "    train_paths = []\n",
    "    train_labels = []\n",
    "    val_paths = []\n",
    "    val_labels = []\n",
    "\n",
    "    with open(train_file_path) as train_fp:\n",
    "        for line in train_fp:\n",
    "            img_path, class_ids = line.split()\n",
    "            train_paths.append(img_path)\n",
    "            train_labels.append(int(class_ids))\n",
    "\n",
    "    with open(val_file_path) as val_fp:\n",
    "        for line in val_fp:\n",
    "            img_path, class_ids = line.split()\n",
    "            val_paths.append(img_path)\n",
    "            val_labels.append(int(class_ids))\n",
    "\n",
    "    with open(classes_file_path) as classes_fp:\n",
    "        class_names = [line.strip() for line in classes_fp]\n",
    "        num_classes = len(class_names)\n",
    "\n",
    "    with open(os.path.join(logs_dir, \"classes.txt\"), 'w') as f:\n",
    "        for item in class_names:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    trainX = load_images(train_paths, image_width, image_height)\n",
    "    trainY = np.array(train_labels)\n",
    "    testX = load_images(val_paths, image_width, image_height)\n",
    "    testY = np.array(val_labels)\n",
    "\n",
    "    # print(trainX)\n",
    "    # print(testX)\n",
    "    # print(trainY)\n",
    "    # print(testY)\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "    trainY = to_categorical(trainY, num_classes=num_classes)\n",
    "    testY = to_categorical(testY, num_classes=num_classes)\n",
    "\n",
    "    return trainX, testX, trainY, testY, class_names\n",
    "\n",
    "if val_file_path is None:\n",
    "    x_train, x_test, y_train, y_test, class_names = load_dataset()\n",
    "else:\n",
    "    x_train, x_test, y_train, y_test, class_names = load_train_val()\n",
    "\n",
    "if binary_classification:\n",
    "    y_train = y_train[:, 1]\n",
    "    y_test = y_test[:, 1]\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "optimizer = Adam(lr=init_lr, decay=init_lr / num_epochs)\n",
    "model = compile_model(optimizer, 1 if binary_classification else num_classes, full_training,\n",
    "                           resume, binary_classification)\n",
    "\n",
    "# model.compile(loss=\"binary_crossentropy\",optimizer=opt,\n",
    "# \tmetrics=[\"accuracy\"])\n",
    "# model.summary()\n",
    "\n",
    "print(x_train, x_test, y_train, y_test, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train, y_train)\n",
    "print(init_lr)\n",
    "print(len(x_train), len(y_train))\n",
    "print(len(x_test), len(y_test))\n",
    "print(len(x_train) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "nervous-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "[INFO] serialized model name: logs/vegetables_001_lenet_013model.{epoch:02d}-{val_loss:.2f}.hdf5\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.7119 - accuracy: 0.3750 - val_loss: 0.7090 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70899, saving model to logs/vegetables_001_lenet_013/model.01-0.71.hdf5\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7421 - accuracy: 0.1429 - val_loss: 0.6379 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.70899 to 0.63794, saving model to logs/vegetables_001_lenet_013/model.02-0.64.hdf5\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6409 - accuracy: 0.3438 - val_loss: 0.6426 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.63794\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6380 - accuracy: 0.5714 - val_loss: 0.6534 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.63794\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6529 - accuracy: 0.3750 - val_loss: 0.6562 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.63794\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6481 - accuracy: 0.4286 - val_loss: 0.6546 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.63794\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6495 - accuracy: 0.4286 - val_loss: 0.6503 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.63794\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6462 - accuracy: 0.3438 - val_loss: 0.6452 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.63794\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6371 - accuracy: 0.3750 - val_loss: 0.6422 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.63794\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6417 - accuracy: 0.3125 - val_loss: 0.6430 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.63794\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6769 - accuracy: 0.1429 - val_loss: 0.6416 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.63794\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6208 - accuracy: 0.4286 - val_loss: 0.6403 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.63794\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6410 - accuracy: 0.3125 - val_loss: 0.6390 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.63794\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6377 - accuracy: 0.3125 - val_loss: 0.6383 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.63794\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6344 - accuracy: 0.3438 - val_loss: 0.6382 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.63794\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6390 - accuracy: 0.2812 - val_loss: 0.6385 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.63794\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6377 - accuracy: 0.3125 - val_loss: 0.6386 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.63794\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6312 - accuracy: 0.2857 - val_loss: 0.6385 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.63794\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6334 - accuracy: 0.3438 - val_loss: 0.6376 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.63794 to 0.63758, saving model to logs/vegetables_001_lenet_013/model.19-0.64.hdf5\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6348 - accuracy: 0.3438 - val_loss: 0.6361 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.63758 to 0.63614, saving model to logs/vegetables_001_lenet_013/model.20-0.64.hdf5\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6370 - accuracy: 0.3125 - val_loss: 0.6348 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.63614 to 0.63482, saving model to logs/vegetables_001_lenet_013/model.21-0.63.hdf5\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6282 - accuracy: 0.4375 - val_loss: 0.6334 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.63482 to 0.63342, saving model to logs/vegetables_001_lenet_013/model.22-0.63.hdf5\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6347 - accuracy: 0.4286 - val_loss: 0.6323 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.63342 to 0.63228, saving model to logs/vegetables_001_lenet_013/model.23-0.63.hdf5\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6248 - accuracy: 0.4286 - val_loss: 0.6318 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.63228 to 0.63182, saving model to logs/vegetables_001_lenet_013/model.24-0.63.hdf5\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6239 - accuracy: 0.5000 - val_loss: 0.6313 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.63182 to 0.63133, saving model to logs/vegetables_001_lenet_013/model.25-0.63.hdf5\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6237 - accuracy: 0.5000 - val_loss: 0.6311 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.63133 to 0.63108, saving model to logs/vegetables_001_lenet_013/model.26-0.63.hdf5\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5954 - accuracy: 0.5714 - val_loss: 0.6303 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.63108 to 0.63034, saving model to logs/vegetables_001_lenet_013/model.27-0.63.hdf5\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6223 - accuracy: 0.4375 - val_loss: 0.6316 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.63034\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6170 - accuracy: 0.4062 - val_loss: 0.6328 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.63034\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6037 - accuracy: 0.4375 - val_loss: 0.6330 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.63034\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6030 - accuracy: 0.4688 - val_loss: 0.6322 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.63034\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6038 - accuracy: 0.5714 - val_loss: 0.6331 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.63034\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5938 - accuracy: 0.5312 - val_loss: 0.6385 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.63034\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6044 - accuracy: 0.4286 - val_loss: 0.6465 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.63034\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6171 - accuracy: 0.2857 - val_loss: 0.6580 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.63034\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6320 - accuracy: 0.4286 - val_loss: 0.6712 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.63034\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6165 - accuracy: 0.4286 - val_loss: 0.6731 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.63034\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7023 - accuracy: 0.2857 - val_loss: 0.6673 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.63034\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6132 - accuracy: 0.4286 - val_loss: 0.6605 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.63034\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6498 - accuracy: 0.2857 - val_loss: 0.6529 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.63034\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6422 - accuracy: 0.2857 - val_loss: 0.6524 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.63034\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5688 - accuracy: 0.4688 - val_loss: 0.6601 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.63034\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6241 - accuracy: 0.5000 - val_loss: 0.6658 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.63034\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7017 - accuracy: 0.4286 - val_loss: 0.6573 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.63034\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4797 - accuracy: 0.7143 - val_loss: 0.6503 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.63034\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5707 - accuracy: 0.5714 - val_loss: 0.6438 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.63034\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6290 - accuracy: 0.2857 - val_loss: 0.6389 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.63034\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6097 - accuracy: 0.4688 - val_loss: 0.6369 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.63034\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5700 - accuracy: 0.2857 - val_loss: 0.6350 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.63034\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5387 - accuracy: 0.8571 - val_loss: 0.6322 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.63034\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6278 - accuracy: 0.4286 - val_loss: 0.6312 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.63034\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5535 - accuracy: 0.5714 - val_loss: 0.6301 - val_accuracy: 0.2667\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.63034 to 0.63007, saving model to logs/vegetables_001_lenet_013/model.52-0.63.hdf5\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6070 - accuracy: 0.5714 - val_loss: 0.6380 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.63007\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5697 - accuracy: 0.5000 - val_loss: 0.6478 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.63007\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6513 - accuracy: 0.1429 - val_loss: 0.6458 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.63007\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6319 - accuracy: 0.2857 - val_loss: 0.6353 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.63007\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5721 - accuracy: 0.5312 - val_loss: 0.6196 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.63007 to 0.61956, saving model to logs/vegetables_001_lenet_013/model.57-0.62.hdf5\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5568 - accuracy: 0.5000 - val_loss: 0.6040 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.61956 to 0.60399, saving model to logs/vegetables_001_lenet_013/model.58-0.60.hdf5\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5291 - accuracy: 0.5714 - val_loss: 0.5934 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.60399 to 0.59338, saving model to logs/vegetables_001_lenet_013/model.59-0.59.hdf5\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5795 - accuracy: 0.5312 - val_loss: 0.5879 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.59338 to 0.58790, saving model to logs/vegetables_001_lenet_013/model.60-0.59.hdf5\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5700 - accuracy: 0.4286 - val_loss: 0.5812 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.58790 to 0.58120, saving model to logs/vegetables_001_lenet_013/model.61-0.58.hdf5\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4732 - accuracy: 0.7143 - val_loss: 0.5824 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.58120\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5942 - accuracy: 0.2857 - val_loss: 0.5909 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.58120\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6971 - accuracy: 0.4286 - val_loss: 0.5764 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.58120 to 0.57641, saving model to logs/vegetables_001_lenet_013/model.64-0.58.hdf5\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6115 - accuracy: 0.4286 - val_loss: 0.5719 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.57641 to 0.57191, saving model to logs/vegetables_001_lenet_013/model.65-0.57.hdf5\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5674 - accuracy: 0.5714 - val_loss: 0.5833 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.57191\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5672 - accuracy: 0.5714 - val_loss: 0.6295 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.57191\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4898 - accuracy: 0.5714 - val_loss: 0.6979 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.57191\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6645 - accuracy: 0.5714 - val_loss: 0.6788 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.57191\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5706 - accuracy: 0.4375 - val_loss: 0.6363 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.57191\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5453 - accuracy: 0.5312 - val_loss: 0.5955 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.57191\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5103 - accuracy: 0.5625 - val_loss: 0.5688 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.57191 to 0.56881, saving model to logs/vegetables_001_lenet_013/model.72-0.57.hdf5\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5049 - accuracy: 0.5938 - val_loss: 0.5566 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.56881 to 0.55664, saving model to logs/vegetables_001_lenet_013/model.73-0.56.hdf5\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5493 - accuracy: 0.5714 - val_loss: 0.5529 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.55664 to 0.55291, saving model to logs/vegetables_001_lenet_013/model.74-0.55.hdf5\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5381 - accuracy: 0.5938 - val_loss: 0.5549 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.55291\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4949 - accuracy: 0.5714 - val_loss: 0.5846 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.55291\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5192 - accuracy: 0.5312 - val_loss: 0.6289 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.55291\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6071 - accuracy: 0.5714 - val_loss: 0.6544 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.55291\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4894 - accuracy: 0.4286 - val_loss: 0.6388 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.55291\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5164 - accuracy: 0.5312 - val_loss: 0.6048 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.55291\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5163 - accuracy: 0.4688 - val_loss: 0.5689 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.55291\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4850 - accuracy: 0.7812 - val_loss: 0.5467 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.55291 to 0.54673, saving model to logs/vegetables_001_lenet_013/model.82-0.55.hdf5\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4827 - accuracy: 0.6250 - val_loss: 0.5379 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.54673 to 0.53793, saving model to logs/vegetables_001_lenet_013/model.83-0.54.hdf5\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3516 - accuracy: 0.8571 - val_loss: 0.5427 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.53793\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4853 - accuracy: 0.5938 - val_loss: 0.5705 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.53793\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5696 - accuracy: 0.2857 - val_loss: 0.6107 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.53793\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4890 - accuracy: 0.6250 - val_loss: 0.6225 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.53793\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4910 - accuracy: 0.5714 - val_loss: 0.6656 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.53793\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5106 - accuracy: 0.7143 - val_loss: 0.6686 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.53793\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4376 - accuracy: 0.6562 - val_loss: 0.6412 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.53793\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3979 - accuracy: 0.7143 - val_loss: 0.6095 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.53793\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2063 - accuracy: 0.8571 - val_loss: 0.6120 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.53793\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4198 - accuracy: 0.5714 - val_loss: 0.6179 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.53793\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4674 - accuracy: 0.7188 - val_loss: 0.5860 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.53793\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6181 - accuracy: 0.5714 - val_loss: 0.5387 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.53793\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - accuracy: 0.5714 - val_loss: 0.5320 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.53793 to 0.53199, saving model to logs/vegetables_001_lenet_013/model.96-0.53.hdf5\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4703 - accuracy: 0.7143 - val_loss: 0.6077 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.53199\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4297 - accuracy: 0.7500 - val_loss: 0.6811 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.53199\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6085 - accuracy: 0.7143 - val_loss: 0.5123 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.53199 to 0.51227, saving model to logs/vegetables_001_lenet_013/model.99-0.51.hdf5\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3012 - accuracy: 0.8571 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.51227 to 0.46849, saving model to logs/vegetables_001_lenet_013/model.100-0.47.hdf5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_callbacks():\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=100, verbose=1)\n",
    "#     return [\n",
    "#         reduce_lr, early_stopping, *make_logging_callbacks(logs_dir)\n",
    "#     ]\n",
    "    return [\n",
    "        *make_logging_callbacks(logs_dir)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "from lenet import LeNet\n",
    "base_model = LeNet.build(width=image_width, height=image_height, depth=3, classes=num_classes)\n",
    "\n",
    "optimizer = Adam(lr=init_lr, decay=init_lr / num_epochs)\n",
    "model = compile_model(optimizer, 1 if binary_classification else num_classes, full_training,\n",
    "                           resume, binary_classification)\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "history = model.fit_generator(\n",
    "    aug.flow(x_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // batch_size,\n",
    "    epochs=num_epochs,\n",
    "    # validation_steps=800,\n",
    "    verbose=1,\n",
    "    callbacks=make_callbacks(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-poetry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

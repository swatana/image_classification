{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "conceptual-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import argparse\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import cv2\n",
    "\n",
    "import imutils\n",
    "from imutils import paths\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from test_generator import test_generator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn import metrics\n",
    "\n",
    "from utils import get_unused_dir_num\n",
    "from test_utils import CvPutJaText\n",
    "\n",
    "import json\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bizarre-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NotFoundError(Exception):\n",
    "    pass\n",
    "\n",
    "def get_unused_result_dir_num(pref):\n",
    "    os.makedirs('./results', exist_ok=True)\n",
    "    dir_list = os.listdir(path='./results')\n",
    "    for i in range(1000):\n",
    "        search_dir_name = pref + \"_\" + '%03d' % i\n",
    "        if search_dir_name not in dir_list:\n",
    "            return search_dir_name\n",
    "    raise NotFoundError('Error')\n",
    "\n",
    "\n",
    "def _read_image_path_and_label_from_test_file(test_file):\n",
    "    with open(test_file) as f:\n",
    "        for line in f:\n",
    "            yield line.split()\n",
    "\n",
    "\n",
    "def create_polygon_json_from_mask(gray, filename, class_id=None):\n",
    "    _, contours, hierarchy = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    line = filename\n",
    "\n",
    "    for cnt in contours:\n",
    "        if len(cnt) <= 2:\n",
    "            continue\n",
    "\n",
    "        cnt = cnt.flatten()\n",
    "\n",
    "        line += \" \"\n",
    "        line += \",\".join(list(map(str, cnt)))\n",
    "        if class_id is not None:\n",
    "            line += \",\" + str(class_id)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "german-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_images(model, class_names, image_path_list=None, image_path=None, imshow=False, predict_dir=None,\n",
    "                   model_image_size=(28, 28), image_class=None):\n",
    "\n",
    "    if image_path_list is None:\n",
    "        image_path_list = list(paths.list_images(image_path)) if os.path.isdir(\n",
    "            image_path) else [image_path]\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    preds = []\n",
    "    for path in image_path_list:\n",
    "        image = cv2.imread(path)\n",
    "        modelsize_image = cv2.resize(image, model_image_size)\n",
    "        output_image = imutils.resize(image, width=400)\n",
    "\n",
    "        # pre-process the image for classification\n",
    "        orig = cv2.resize(image, model_image_size).astype(\"float\")\n",
    "        image = orig / 255.0\n",
    "        orig = cv2.cvtColor(img_to_array(orig), cv2.COLOR_BGR2RGB)\n",
    "        image = np.expand_dims(img_to_array(image), axis=0)\n",
    "\n",
    "        # classify the input image\n",
    "        predict = model.predict(image)\n",
    "        \n",
    "        \n",
    "\n",
    "        preds.append(predict[0])\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "logical-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontPIL = \"Dflgs9.ttc\"\n",
    "font_path = fontPIL\n",
    "\n",
    "\n",
    "model_path = 'logs/vegetables_000_lenet_005/model.01-0.64.hdf5'\n",
    "test_data_path = 'test_data/vegetables_000/test_list.txt'\n",
    "model_image_size = (28, 28)\n",
    "\n",
    "model_path = 'logs/smoke_000_inception_v3_000/model.68-0.18.hdf5'\n",
    "test_data_path = 'test_data/smoke_000/test_list.txt'\n",
    "model_image_size = (299, 299)\n",
    "\n",
    "model_path = 'logs/smoke2_000_lenet_000/model.97-0.36.hdf5'\n",
    "test_data_path = 'test_data/smoke2_000/test_list.txt'\n",
    "model_image_size = (51, 28)\n",
    "\n",
    "# model_path = 'logs/smoke2_000_inception_v3_001/model.20-0.64.hdf5'\n",
    "# test_data_path = 'test_data/smoke2_000/test_list.txt'\n",
    "# model_image_size = (299, 299)\n",
    "\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "formal-dressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_input (InputLayer)    [(None, 28, 51, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 51, 20)        1520      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 51, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 25, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 25, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 25, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 12, 50)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               2100500   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 2,128,078\n",
      "Trainable params: 2,128,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "baking-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.dirname(model_path)\n",
    "test_data_dir = os.path.dirname(test_data_path)\n",
    "with open(os.path.join(model_dir, \"config.json\")) as f:\n",
    "    config = json.load(f)\n",
    "class_path = os.path.join(model_dir, \"classes.txt\")\n",
    "with open(class_path) as fp:\n",
    "    class_names = [line.strip() for line in fp]\n",
    "CLASS = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "designed-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp = model.layers[0].input\n",
    "out = model.layers[-2].output\n",
    "predictions = Dense(2, activation='sigmoid', name='dense_2')(out)\n",
    "model_sigmoid = Model(inp, predictions)\n",
    "# model_sigmoid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "appropriate-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_data_path = 'test_data/smoke2_000/train_list_2.txt'\n",
    "test_path = test_data_path\n",
    "contents = _read_image_path_and_label_from_test_file(test_path)\n",
    "# result[l1][l2] : the number of images witch is predicted as l1, the true label is l2\n",
    "result = np.zeros((CLASS, CLASS), dtype=int)\n",
    "\n",
    "labels = []\n",
    "predicts = []\n",
    "pred_labs = []\n",
    "stats = []\n",
    "\n",
    "image_path_list = []\n",
    "for content in contents:\n",
    "    image_path_list.append(content[0])\n",
    "    labels.append(int(content[1]))\n",
    "\n",
    "predicts = predict_images(model=model, image_path_list=image_path_list,\n",
    "                          class_names=class_names, predict_dir=predict_dir, model_image_size=model_image_size)\n",
    "predicts = np.array(predicts)\n",
    "\n",
    "\n",
    "predicts_sigmoid = predict_images(model=model_sigmoid, image_path_list=image_path_list,\n",
    "                          class_names=class_names, predict_dir=predict_dir, model_image_size=model_image_size)\n",
    "predicts_sigmoid = np.array(predicts_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ongoing-basket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60957724, 0.3904228 ], dtype=float32)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "veterinary-horse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "angry-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [289 261]\n",
      "[[289 232]\n",
      " [205 216]]\n",
      "[289 261]\n",
      "accuracy 0.20545454545454545 recall 1.0 precision 0.5547024952015355\n",
      "誤検知 0.4452975047984645 検知漏れ 0.0\n",
      "accuracy 0.20545454545454545 recall 0.8275862068965517 precision 0.5130641330166271\n",
      "誤検知 0.4869358669833729 検知漏れ 0.1724137931034483\n"
     ]
    }
   ],
   "source": [
    "true_labs = []\n",
    "img_labs = []\n",
    "\n",
    "result = np.zeros((CLASS, CLASS), dtype=int)\n",
    "cnt_labels = np.zeros((CLASS), dtype=int)\n",
    "thre_score = 0.01\n",
    "# thre_score = 0.001\n",
    "# thre_score = None\n",
    "# pn = np.zeros((CLASS, 2, 2), dtype=int)\n",
    "# print(predicts[0])\n",
    "# print(labels[0])\n",
    "u, cnt_labels = np.unique(labels, return_counts=True)\n",
    "print(u, cnt_labels)\n",
    "for i, (pred, lab, image_path) in enumerate(zip(predicts, labels, image_path_list)):\n",
    "# for i, (pred, lab, image_path) in enumerate(zip(predicts_sigmoid, labels, image_path_list)):\n",
    "#     cnt_labels[lab] += 1\n",
    "    if thre_score == None:\n",
    "        argmax = pred.argmax()\n",
    "        pred_labs.append(argmax)\n",
    "        true_labs.append(lab)\n",
    "        img_labs.append(image_path)\n",
    "        result[argmax][lab] += 1\n",
    "    else:\n",
    "        for j, p in enumerate(pred):\n",
    "            if p > thre_score:\n",
    "                pred_labs.append(p)\n",
    "                true_labs.append(lab)\n",
    "                img_labs.append(image_path)\n",
    "                result[j][lab] += 1\n",
    "print(result)\n",
    "print(cnt_labels)\n",
    "all_sum = len(predicts)\n",
    "# col_sum[l] : count of whose true label is l\n",
    "col_sum = np.sum(result, axis=0)\n",
    "# row_sum[l] : count of whose predicted label is l\n",
    "row_sum = np.sum(result, axis=1)\n",
    "all_score = []\n",
    "all_true = []\n",
    "for i in range(CLASS):\n",
    "    recall = float(result[i][i]) / cnt_labels[i] if col_sum[i] != 0 else -1\n",
    "    precision = float(result[i][i]) / row_sum[i] if row_sum[i] != 0 else -1\n",
    "    specificity = float(\n",
    "        all_sum + result[i][i] - col_sum[i] - row_sum[i]) / (all_sum - col_sum[i])\n",
    "    f_value = 2 * recall * precision / \\\n",
    "        (recall + precision) if recall != -1 and precision != -1 else -1\n",
    "    accuracy = (all_sum + 2 * result[i][i] - row_sum[i] -\n",
    "                col_sum[i]) / all_sum if all_sum != 0 else -1\n",
    "    print('accuracy',accuracy,'recall', recall, 'precision', precision)\n",
    "    print('誤検知',1-precision,'検知漏れ', 1-recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-leisure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-creek",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
